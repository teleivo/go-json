# TODO

* set the scanner.Error function so errors are not printed to Stderr
* support unicode by using text/scanner in lexer
* parse a number
* think about what string literal the lexer should return in case of error
  for example when lexing `2.a3`, should it be `2` or `2.`? or simply an empty string
  since error will be non-nil?
* ignore linting errors in test that are false-positives
* adapt ParseError to an interface? failing to parse a number is different to getting un unexpected token (maybe UnexpectedTokenErr)
  how to I treat lexer errors? Should I wrap them?
* create a lexer error type with more context
* I feel like I am not advancing past the ] in parseArray. On the other hand, it seems to parse nested array well
* add String() string to ast Node interface
* would TokenType also benefit from a String(), printing all caps TRUE, FALSE, ... in errors is not friendly :)
* parse an object
* adapt tests to use maps instead of test slices, so the order of tests cannot hide potential bugs

## IDEAS

* try out fuzzing
* provide context to error messages. in what file, line, col is the error.
* write a CLI that takes a JSON from stdin to parse it
* try out fuzzing for testing
* use the parser to write a JSON stats CLI. How many arrays, objects are in the
JSON? How deeply nested is the JSON? How many nodes per type?
